{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List, Union, Any\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database: Configuration\n",
    "\n",
    "PGVector instance running on a local Docker container. Connection string uses psycopg adapter with specific port mapping (6024) to enable PostgreSQL connectivity in the local network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = \"postgresql+psycopg://langchain:langchain@192.168.0.53:6024/langchain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database: Vector Store\n",
    "\n",
    "Configures PGVector store with:\n",
    "- Local GPU-accelerated embeddings via Nomic's text embedding model v1.5\n",
    "- Vector storage in dedicated collection with JSONB metadata support\n",
    "- Native pgvector extension for efficient similarity search operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PGVector(\n",
    "    embeddings=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\", device=\"gpu\"),\n",
    "    collection_name=\"database\",\n",
    "    connection=connection,\n",
    "    use_jsonb=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: PDF Processing\n",
    "\n",
    "Implements PDF document loading and text splitting:\n",
    "- Load PDFs from 'data' directory using PyPDFDirectoryLoader\n",
    "- Splits text into chunks using recursive character splitter\n",
    "- Configured with 1000-character chunks and 200-character overlap for context preservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(path=\"data\")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database: Document Indexing\n",
    "\n",
    "Indexes processed document chunks into PGVector store for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caaf18d0-287b-44b5-bf71-d66c510292bc',\n",
       " 'fcafdaf3-fba2-447f-bbe5-e54eba3c9d11',\n",
       " '28eb1d19-5cc4-4f49-9dac-e0d31128017e',\n",
       " '2381aa29-d514-4106-8cb7-5ccdbdc08c86',\n",
       " '1ae4df8c-258f-4794-811d-4925714cbb88',\n",
       " '4a658baf-8d0d-47f4-bcd0-02d432379eae',\n",
       " '47cea0ba-fe4d-4569-9149-d496919a130a',\n",
       " 'cea2dce4-7bb7-4379-b236-a63490eecd6a',\n",
       " '29640434-0dbb-4aff-b2d5-2cb5135a7ffd',\n",
       " 'bf2934f8-7ec5-4b44-b224-11401d0455d7',\n",
       " '48cd55c2-f7c7-4a87-b0e6-0aa8b7834910',\n",
       " '109729e0-1d12-4516-9f57-3221ababc2b1',\n",
       " '7c6597b2-e357-4560-abe1-843b1de5bca1',\n",
       " '9a0dc9eb-4aa5-4c02-b193-5c4915ba7b91',\n",
       " 'eb3d2e84-ee62-41e8-b29d-10dae2408f24',\n",
       " '3904e44a-8dda-45df-8a68-8daee6e7a4e2',\n",
       " 'c64e44af-6a5f-475b-be58-9a8e8b0861ee',\n",
       " '75e6aeec-57a8-4aab-8c83-a6108570efe4',\n",
       " '6d3e1884-ea09-4111-9ad9-421989075245',\n",
       " '01f571de-11e1-49f8-9406-38f396aab389',\n",
       " '24d9f916-df05-401a-853d-0da894e8c890',\n",
       " '8128de4f-f3d1-4f09-84f5-0c7ac28fd432',\n",
       " '9a31ba3e-ae3b-4fc2-ba12-b8b7df660b35',\n",
       " 'b4787352-0965-47b7-9cff-01f2761100bb',\n",
       " '5f7c8372-a613-406b-b060-69f472843d1f',\n",
       " '2a07279c-8d78-48aa-a4a1-e0e8539a8553',\n",
       " '2c62243c-8dd9-4330-be20-c8435b0f5c69',\n",
       " '75b4ab30-12be-4769-9cc6-eecb8d3836d2',\n",
       " '2b1b0d68-04be-4b51-b48d-9803e297adb0',\n",
       " '1a79ed72-356f-4d4e-9bf1-661a51482c8b',\n",
       " '69a2fe56-762c-4bf4-ae97-309e7aecf457',\n",
       " '76643504-3ede-4ce1-bf55-01e67dcbb2e0',\n",
       " '1bcaf8f7-845a-47a1-b9c6-595921b7c28b',\n",
       " 'a429826f-2762-473e-a118-761f0122a7f4',\n",
       " '74416415-4594-447b-9c25-64e97bc8b1ae',\n",
       " 'c3eef0f5-fc8d-4159-8248-f84e1ca16ef4',\n",
       " '9440cf79-3d04-478d-9acf-e45a49dcd29d',\n",
       " '6b178bdf-7afd-416d-89bc-3adfad8498b7',\n",
       " 'c373c228-856d-4cd5-8fd9-4b5577c32a88',\n",
       " '442debd9-a9f1-4492-9bfc-8b43409d2f58',\n",
       " 'af9dbcbd-337b-4518-860b-2c36353a4538',\n",
       " '0f86e59f-e6e4-40d3-afc4-e3812f119adf',\n",
       " 'a2b53a0d-5017-4e23-93f8-8e283f9484fd',\n",
       " '232374e9-38e3-4d28-99fb-c8f9995d4c6a',\n",
       " '6d331228-22e6-4e03-93d0-0a2fa3f0d7ff',\n",
       " 'be7c469b-a5e0-4461-afaf-eca62b472d6b',\n",
       " '6068b67c-88ed-4de5-aa1d-2ad1934e3f30',\n",
       " '17d6fe96-8578-452c-b9e0-b4e7b1cbd28f',\n",
       " '1e601895-5e0f-415b-81a8-3f45c1f41f00',\n",
       " 'cae0732b-814e-4c36-ae69-17883442985a',\n",
       " '59634c50-a7e9-410c-b4c1-5391d0ec2d00',\n",
       " '94a0f79e-d685-4b29-9059-805296d967bc',\n",
       " '60b96ab0-cc82-46bf-a908-10053974607a',\n",
       " 'ebd31d78-7ddb-4577-a6d6-6bfd3358b550',\n",
       " 'b562606e-71bb-4dbf-94bc-d92463c2836a',\n",
       " 'e7cf2d47-53af-4bee-a91f-13c93641c4ad',\n",
       " '03f79a94-0c4f-41a3-a24f-b32ea7267f58',\n",
       " 'b5dd30bc-6d31-462b-8990-1ea93d5d3dc6',\n",
       " '15769652-3b65-452c-82f7-f5727292f082',\n",
       " '68b2d369-18eb-4794-93ae-dc64c8af314f',\n",
       " '318f1a71-7b88-4df1-9f78-c6cf58bee7a2',\n",
       " '3b0513fe-b8fd-49ba-916d-bd37a8a19bf2',\n",
       " 'e00594fd-b835-4270-b9ad-b0a78ec3d185',\n",
       " '9bbafc92-a05d-431f-85d6-930533d9c20c',\n",
       " 'e7ad5313-4574-45f2-ab21-3ee104c1cd55',\n",
       " 'd2b8661d-fb34-4368-87ee-7daf713ba9b3',\n",
       " '30b34bf1-5b8f-40c1-af42-42f8831d7cc8',\n",
       " '2f10b4db-82ec-4be1-99bc-c341fe921392',\n",
       " 'e80d193e-1c6c-4dc8-85d8-47871797b553',\n",
       " '9e4ef62a-37f4-4fcd-aea3-aea3473b26d9',\n",
       " 'f3c086c6-e4c5-49f1-9fd2-1bf6ea88ecff',\n",
       " 'f72f4946-fc78-4593-8c4c-80b866625ae7',\n",
       " 'edbb3b35-9fdb-4ab3-a315-ec726ffcffec',\n",
       " '9ce2a7a5-3085-4463-b3bf-d6fbc12373ae',\n",
       " 'dcf5cc8c-3479-4e22-b976-76bf8c1effaa',\n",
       " '25b82bf2-59ce-4ba9-9f7c-f544a2f4136e',\n",
       " '411fbb79-1c43-4e67-b0eb-48e14f44ad87',\n",
       " 'a99b07ee-830c-4050-81eb-e85a217e98ff',\n",
       " '2432c17d-0459-4c8b-9002-2da289bb96fc',\n",
       " '395181f3-3d3a-4f71-aebd-aba2a9f9cc76',\n",
       " '664f179d-7355-43b3-9909-070f594ebe82',\n",
       " 'f79c5138-3011-422d-945a-ff2fa8a9193d',\n",
       " '697d7608-dc5f-4be2-9cb8-b0f922c7c1e9',\n",
       " '7f29593a-1f1f-4982-a169-29310f1bccd9',\n",
       " '2741c59f-196c-4b34-806b-2974554743af',\n",
       " 'a974d7d1-a4e7-4585-a69e-3a0d97d59c39',\n",
       " '3087db6e-9603-4869-8440-034d3bda93fb',\n",
       " '693e9a98-9045-41d6-b13c-ecd0ac3efa49',\n",
       " '6eae2660-5973-4de4-9123-4378274007fa',\n",
       " '7ef89696-5bde-4d18-a727-1015bc2024b3',\n",
       " 'f978c2cb-f902-4bd7-93d4-121331e5174e',\n",
       " 'ed7bb87a-6760-4e5a-8f18-7a27fe65e306',\n",
       " 'a0d03296-8554-4d1a-95dd-1a899982cce1',\n",
       " '236af82e-e505-44fc-a473-2c28a2cdb97c',\n",
       " '3c0b554e-3766-4105-95b0-b2342e46c2c7',\n",
       " '33280fe4-6155-4158-ab1e-bed66b219999',\n",
       " 'a2f9342b-4fca-4db6-be12-149f5e0e591b',\n",
       " '84920618-23c0-45d8-b99e-c92c66c5c5a7',\n",
       " '28b2e5f9-e244-40d8-a110-62f6fe5227c8',\n",
       " 'b28130f6-11be-4a86-b400-12094ce99f48',\n",
       " '85aecfa6-c400-41ac-9b82-0fdb49926606',\n",
       " '6ca43555-e09b-4375-b4bc-97541ef682f5',\n",
       " 'cb9f3d64-c297-4842-a691-2a4fada9670b',\n",
       " '57f7125d-2b82-4c96-afa2-91907bb3a3ee',\n",
       " '9b19caa8-0de8-4e68-acc4-cc7893186059',\n",
       " 'b2a0575f-c4a2-4483-a7d8-7f2414ac8a04',\n",
       " '6114e04a-83ff-4762-9bf0-6f1608c59725',\n",
       " '988e7e8c-728a-4508-8ba2-5fb3e40629e9',\n",
       " '87535f90-83cd-4387-9983-2b5eed1cb25d',\n",
       " '3081f2f8-319e-4aa3-b989-d585445e060d',\n",
       " 'a4b9552d-1729-45e8-9afc-6b54df475341',\n",
       " 'e4ec1a86-7486-49ce-8b58-7ec2805bd7d3',\n",
       " 'e1b28d63-4752-42d2-929a-1d68ce10ba94',\n",
       " 'b5eda8e0-c1e1-4fd3-91ac-51f298404cb6',\n",
       " '52f44efd-1b1f-4645-be93-c677ab25dcb0',\n",
       " '889ad754-ff92-43bc-97ae-18f861d36435',\n",
       " '9ed798d5-1e51-4ab2-8899-2795df10e7f9',\n",
       " '96beb956-711e-474b-a67b-d3dd03adecc8',\n",
       " '93066206-1ba3-4ac4-9096-0b9936c64530',\n",
       " '3a862910-1e5c-45cf-943d-a1ef05b5c1ba',\n",
       " '3f730276-0fb9-47f2-ad9a-944b5f7458e3',\n",
       " '4f93b69d-b4ef-465e-aa23-8d745782e861',\n",
       " '264c9d56-57fd-4380-954a-377ed1784c4b',\n",
       " '0a095cc5-cd89-4005-a9ad-f7f3f2fe4081',\n",
       " '70e999c1-bb16-4a0c-a278-4c66e462066a',\n",
       " '8a7b7045-b29a-482c-a5a9-7cf5c63a646b',\n",
       " '806cf6f6-336e-4273-9324-464aab1f34cd',\n",
       " '47d33281-ed0e-475a-83d5-41c84b264663',\n",
       " '89318c30-c019-4bdb-baed-5143783902b1',\n",
       " 'a6c6ab78-b0a7-41f8-af92-08bc4c099567',\n",
       " 'b8d6dec9-8b60-4aca-b935-c2b22192db18',\n",
       " 'aeba4074-0010-4ce2-9c3e-fbe95f2065d6',\n",
       " '4ad4138f-f708-4b35-8039-d0e07c6a0a7f',\n",
       " '1e3f1c01-1ee2-479c-bfa7-7881a4d62753',\n",
       " '136e87cb-e555-459c-893a-00f45e3202cf',\n",
       " '2013cb6b-4de4-48f6-af80-b2a6a09d16ae',\n",
       " '8bf04dfc-3868-4ac5-b99e-d8eb8ea526c0',\n",
       " 'd49b7f89-ad6f-4c3f-a232-67d45f6592c2',\n",
       " 'f1d555ab-3612-48d1-b580-50b8a9df5e5e',\n",
       " '7c6a4b17-0eca-491a-b20c-403f23f17dd7',\n",
       " '989f6898-e651-4056-b49b-140c41132830',\n",
       " '0803db4a-433f-41e7-9f7d-c9ee73348051',\n",
       " 'c7050048-d915-45aa-b5de-cea32102b1d7',\n",
       " '3a196ec1-1641-4a0a-9fd0-dca0cb36747e',\n",
       " '8106ae22-9136-45ba-bbf5-7b49d77a0958',\n",
       " 'c3f6fcdd-8a03-4913-9800-96cbadd9e2da',\n",
       " 'f0d9e931-e4b5-4c4a-b683-dd4ab849f909',\n",
       " '22b6d8dd-5497-4d68-8311-fbb7ccc5531c',\n",
       " '34fcaf1d-d837-4f4e-b789-8f0913ed2f37',\n",
       " 'cd0d21f2-153a-447a-9977-4e71952b4ee7',\n",
       " '5a4d6395-5d89-466e-97f9-b6b3cc6fd268',\n",
       " '3438459f-75cf-4004-b0e2-e38507730c40',\n",
       " 'c3498ec5-0243-46d2-a8ad-73b91ab81aab',\n",
       " 'ebbb39ee-66fc-4c71-b0de-b6cb4b714d36',\n",
       " '15f42fdc-5492-4f52-8706-41efa1a755d8',\n",
       " '185aeed7-0acb-46a9-bb23-f3ab570c61a3',\n",
       " 'cf648a2f-6bc5-4914-a450-88f3b28e3ed0',\n",
       " 'f9be4ad0-6312-4841-857e-1fc482a9dcfd',\n",
       " '28ff96b3-3f44-4704-8a36-12b59947ea3f',\n",
       " 'e622ed5e-f527-4dfd-bfde-f033386448bc',\n",
       " '0fb0b677-1b4d-47d6-a59a-fbd79ee3c113',\n",
       " 'd690864b-bc55-47c6-9a99-73e364607776',\n",
       " 'b9a6364d-e23e-43b3-9d37-c3f2957a8720',\n",
       " '73cda3cf-fa72-4975-9fd8-ce2ab81032fd',\n",
       " '35143f04-e5cc-45ad-8feb-3c489d80e298',\n",
       " 'd39e2202-4919-4fe6-93a7-2b95c3da0c64',\n",
       " '948d3930-ce19-4f48-90b5-e69941f7b975',\n",
       " '35a5757f-ad7b-4ebb-8bf0-1761e587af1f',\n",
       " 'fa4adfa4-9d4f-4190-b400-6ad53874913d',\n",
       " 'fb674298-713a-48fe-9547-cffc951b5b21',\n",
       " 'eace2198-09b5-45fc-b3a4-f6628dc3b190',\n",
       " '8072c7c1-e8d8-4409-90de-99f05800eebd',\n",
       " '557449b5-660f-4d39-9f43-157ad0b435a3',\n",
       " '67e2b892-557f-49e0-8659-f9b4995eabea',\n",
       " '56f4b1fc-39b7-4dae-b94d-f70a72037101',\n",
       " '2b4186a5-8848-457d-9119-09838de41a40',\n",
       " '34fe5116-f628-4454-9d7c-f7f9d16c8f19',\n",
       " '4f25caad-8eec-48d2-9d55-6b199e87ff26',\n",
       " '597268ca-a1e7-4d95-990d-122a90036d04',\n",
       " '562354f0-3bf5-4c79-807a-9c3f94cd8c92',\n",
       " '7ee34b0d-5767-4827-8d9b-6b7c310c8c92',\n",
       " 'c55d300e-8ee8-44b0-94ba-da3ddedd15e5',\n",
       " '6d5cfc69-569d-4514-98dd-36f458378796',\n",
       " '67515de6-4416-4c91-be50-f80693567026',\n",
       " 'ca61ad5f-b412-41b0-8eff-9540455c2937',\n",
       " '73bc1af8-6af3-4667-b6f3-b3b3e509b700',\n",
       " 'c6883c0c-ce6d-45d7-bfb2-80d665592211',\n",
       " '2bdb26e2-d2c0-4f4a-a728-5339ed88aa5f',\n",
       " '09b5b529-830a-4757-9663-4f9f9497d9d4',\n",
       " 'e768edb3-e525-41b2-82c3-ceacfd966f45',\n",
       " 'b73a0075-b7a8-475a-a6dc-9268d29a741b',\n",
       " 'c4ca6d32-bfac-4bc1-aa63-85ad1515d5bf',\n",
       " '7480b79c-8777-49f6-a8cd-462bfc5e171d',\n",
       " 'dbd0ca61-5725-4c90-a7be-caa38539b7d9',\n",
       " '633f1554-2954-4106-9cc7-06fce9a2342c',\n",
       " '017169b7-3408-4503-9259-319b3f0b33c8',\n",
       " '7f9398f9-d30f-42b7-bac3-65c3d5d7a3d9',\n",
       " '312a061a-0355-4512-b770-74915fab6b27',\n",
       " 'd1cd8d89-0d18-4552-89b6-fbbc103a2de2',\n",
       " '16eacdc1-274a-4296-bfb6-64937ecfebec',\n",
       " 'e7e3473d-6750-4e72-9f51-24f8726e7a29',\n",
       " '5c3babcd-99a5-4d9c-9d57-4cd33b9bb98c',\n",
       " '4e50d086-aa8c-402c-a5df-156c5454e319',\n",
       " 'd06181cb-3fc4-488e-ac4c-95b4aa91a3ea',\n",
       " 'c6dfe98b-2efe-4585-a37f-ec5e9aa47e88',\n",
       " '4706c8e6-6536-4823-92dd-fbc42de2f682',\n",
       " '20f0b401-c322-48cc-8e92-544ba3786b4c',\n",
       " '8d378a32-b97c-4add-9bdd-e78419b18ac3',\n",
       " '270a6840-4dfb-4d4a-9756-363f5634bad8',\n",
       " 'ba5ff5f5-9897-48ad-928b-4a3a0b49d8ad',\n",
       " '59d8a29d-4025-4062-b551-5cfb3df9ccd7',\n",
       " 'c2992c70-29ba-465b-a68f-5af516976daa',\n",
       " 'f0c847cd-87f6-4e7c-b422-8d96ef3795cd',\n",
       " '7019e6e9-5462-4520-9281-efbccea548ba',\n",
       " 'e3f5bc2b-6875-4d4d-bcdf-64cf553d78a5',\n",
       " 'fe04efb5-2620-4ef7-bcbb-c402cf70a7fe',\n",
       " 'e1ec8615-eae7-45e7-a525-4f4d5c0e9cf1',\n",
       " 'f6c85c2d-b6a4-4c6c-a076-329a013d06ee',\n",
       " 'ce862674-3aeb-44d4-9ef1-df186044cecb',\n",
       " '897905c1-c129-4835-824d-e0c6dcf8b224',\n",
       " '0a1cefe3-6d7c-48a6-8a4a-2debe2727093',\n",
       " '3b5a897f-8949-42bc-891e-c4e6bc3d9173',\n",
       " 'ea8201a4-ab31-4fe3-9364-feb9ed858d7b',\n",
       " 'd933df90-052a-49c5-aea2-86cac1725cc0',\n",
       " '6a3041e7-4997-42de-b540-04255d3d538d',\n",
       " '1c3c3324-b1cb-4db7-8b95-efa892d55078',\n",
       " 'f9f674d6-0644-47c3-bf08-ed79133a331a',\n",
       " '161203e5-a9a2-431f-aa56-49fd2e65a8e9',\n",
       " '0a5fd1d5-2313-4d75-b424-61cc40f150d7',\n",
       " '9c36da5f-7a57-4d60-9e55-5ef79d5ef942',\n",
       " 'c6d6c56f-ae97-47b3-935c-6bd673d806f6',\n",
       " 'a0b4dff8-7848-4953-b015-7d13825e988d',\n",
       " 'b23dc0f8-1312-48a6-b73b-85fdf581a07f',\n",
       " 'f9d9db14-18d8-4e4a-8484-90b9eb2fd1a3',\n",
       " '9e70417f-557b-4ef9-bfc7-8ddba2ab4af2',\n",
       " '9c7e2793-bb7a-4a72-acaa-c91257eabf99',\n",
       " '358a380b-2bc5-459b-8709-bbe1af359bc1',\n",
       " 'e4383e67-08a1-4527-b171-6649a65a7396',\n",
       " 'c48a131a-928b-4f66-bc69-46b2eba9655f',\n",
       " '5bc88bd2-b2e4-4a92-a395-a5f682c2160b',\n",
       " '68283a74-0aa3-4b54-93f0-5ea524353909',\n",
       " '78bfe758-a215-411d-99e8-de45df2cda5c',\n",
       " '01e9a54d-b332-4f81-af31-26b99c62481f',\n",
       " '90822dc7-e6eb-4bcd-a038-1d00b80e1031',\n",
       " '3e7c5b9f-9909-48d1-900c-dd8afc9e2796',\n",
       " 'b955ca0b-f40c-4e93-aae1-f9a07ba339fd',\n",
       " '556d1af0-7b75-4f17-b268-1765c596a7be',\n",
       " 'f0f6ed9e-7749-4cbe-bf3f-8edb6102ce22',\n",
       " '244ce768-d263-4427-8ed6-83bdc1053838',\n",
       " 'e9567592-242f-4dfc-bba1-de0140e2ff55',\n",
       " '36437bcd-5c01-4c14-8428-57f66e2be9d1',\n",
       " 'c413eb8f-70b8-4805-a4f4-854a9b46998d',\n",
       " '396b2379-0cc9-4088-b3d5-bfc42c6f0dc7',\n",
       " '8be6b223-ed3c-4982-a8cf-1a332aa07891',\n",
       " '1bcbbe60-c563-4751-bd7e-8e254e3bac41',\n",
       " 'a5be1dcb-6aa3-42b0-b4c7-eea9dfc2cd34',\n",
       " '8e72b65c-1e44-48d6-a11c-a77848615b42',\n",
       " 'ddbd00ac-e6e6-4aac-be0a-612d6419921c',\n",
       " '68a6f9d8-659c-46f0-aa93-d5c0e1666b02',\n",
       " 'ef6151cc-d445-4f9d-9a3b-2ad8fd1d8c1e',\n",
       " '744340f8-34ae-4b52-b104-fb1f820ed1ca',\n",
       " '336c33d8-1ed0-44b9-90c5-71a2ad3154ea',\n",
       " 'dd84bdca-d044-4165-8dd0-72b6a62b0062',\n",
       " '7be3b957-af15-49a8-9c2f-d1cab7fdf059',\n",
       " '79adc9c1-9afd-4078-bea5-b8f8ee5e7490',\n",
       " 'c286a27c-2411-48d2-bc67-0ccb0f7d22bf',\n",
       " '381946a2-f134-4d22-b124-430ff01f8a5c',\n",
       " '9e83cf74-7ad2-405f-8ef6-e60ae34b83d8',\n",
       " '1f3d2910-f9bf-4497-9207-35594affcef1',\n",
       " 'd3b08439-f60e-46f4-ac9a-7d9e14b44cfc',\n",
       " '56ddd50b-8d20-40f3-ad23-23163d4edde5',\n",
       " 'e6a54b9a-c9d2-47da-b6ed-45fb3bbbf084',\n",
       " '4223b350-542d-4323-ba8e-abb0fe52c6da',\n",
       " 'fb161b13-a353-4edd-87c6-013fb28f723b',\n",
       " 'ebfcb18d-1fbc-467e-afab-9c7610f41eb0',\n",
       " 'bd3dbbd6-bd70-4e38-b640-c37e2a2c9ad4',\n",
       " '1ad2c46f-4059-416d-84d3-2a121b238b3f',\n",
       " '943ac713-930f-4fd7-b47f-33ce6d56182d',\n",
       " '1d801dce-939e-4795-bace-692e4b11e8fd',\n",
       " '51c9f40d-9c00-4b9a-ab77-b43ebc487770',\n",
       " '22b101ea-b4a9-440d-a20c-b44f2e9a13cc',\n",
       " '8ba2cbea-77b8-4cce-9145-7e916f647b66',\n",
       " '1e52c7da-0e70-414c-b1ef-9bc88c29cea5',\n",
       " 'f4b6e758-e6d4-4456-8d1a-2ab146219f5a',\n",
       " 'c03596e7-a4c5-4508-b159-2d91938f673d',\n",
       " 'b5412861-82f9-4029-aabd-af25178429c5',\n",
       " 'fbf81328-d07c-4719-a9bb-3f36ae6bc4e0',\n",
       " 'b6fc4a03-0b64-49de-99c9-695e2248be7b',\n",
       " 'cd77b34e-eaab-404b-8097-a049f3cfa0c9',\n",
       " 'dee640bb-149e-4152-a1aa-d7d2164001fa',\n",
       " 'd5bc6259-240d-4588-9e65-1781793fe53e',\n",
       " '5d5344ec-ba76-4fe7-a12f-a0168feff6c5',\n",
       " '4902aee9-bfef-41a5-bb0a-0f2c4faa92ad',\n",
       " '97285a0f-c692-4920-a4c2-7bfac5116300',\n",
       " 'eb462e3d-be16-4bd5-a44e-12882089ae20',\n",
       " '4f4f3bdd-18ec-4308-8fa2-07fff5f9c18c',\n",
       " '4ec772be-e6a6-484d-92e0-ec3fac0d03c7',\n",
       " '00d080d1-87f1-47eb-a342-09bcf30f84a4',\n",
       " '465badef-af7b-4ee4-9503-ac038457cc82',\n",
       " '1a313bb5-6723-4222-b215-969e7f5f47ec',\n",
       " 'cc2b5280-6831-4f86-9ed1-3af1b656d833',\n",
       " '89ef299f-98c5-46c1-9e10-f24073391bcc',\n",
       " 'f0c5db45-d804-4c3e-9d81-57b926c7b5d6',\n",
       " '5865aac2-2f56-4600-9c48-9f3f10ebfc1b',\n",
       " 'af2dd8b9-aef8-4c80-921e-92cf7c1b97ba',\n",
       " '04fdeb04-3423-42b0-ba95-1208b4884f09',\n",
       " '3129e4df-c6ac-47b1-a85b-4a575686e3cf',\n",
       " '07101013-5c4a-45ff-b35d-c28c3277b8cc',\n",
       " '29990858-95ac-4f4c-b0d2-c7a76452fd3f',\n",
       " 'eacbdc60-e2b5-44f5-9dfc-0be772620b2c',\n",
       " '78ef4b0c-1fdc-478c-88a6-5b1d61025bf2',\n",
       " '7defd571-a154-4cc1-a1c1-ab19f95f6772',\n",
       " '63ae1930-a701-43bb-b2a2-613858bf99e1',\n",
       " '035126f7-0ec5-4c3a-9d3d-974e1cc21aad',\n",
       " 'c4d17882-ba2a-41cb-9466-2d7050854ee4',\n",
       " '30343724-06f4-458c-b4aa-b61c1fccc011',\n",
       " '6b7eba49-8adb-4cee-b318-1ecbb32cf404',\n",
       " '74705845-9fcb-4ef5-a0c1-4b9f7b70c2e6',\n",
       " 'afb82049-74ad-4159-99e6-aceb319498ba',\n",
       " '042e872a-f4f8-465d-8344-877c198137e6',\n",
       " 'e69a5130-8435-4425-a24f-f01ee7dc8897',\n",
       " 'cd0b6bd1-4bb6-40e3-88bd-3ca750d7afb0',\n",
       " '1e5bd6a9-3c63-4d41-8892-34a170363423',\n",
       " '328c0e6f-64f9-4be7-a20f-7886003df019',\n",
       " '9a809ad4-7116-4fa9-b400-67f6ecbd8f0f',\n",
       " 'c1d64f66-7d2d-4657-a510-ed70009e6ac7',\n",
       " '388e277f-73d2-4ab5-84af-1ba534e5350e',\n",
       " 'a238e244-0731-4fef-a902-7e1f88282ce1',\n",
       " '87f4676f-fe0b-4024-ad83-4416ff2d76cb',\n",
       " '151a9d47-2bd3-4428-80f3-f4a0c248f757',\n",
       " '33e738ed-7b58-42ff-9fdf-67a56452a174',\n",
       " '49d9316c-3485-434d-83ef-f77ae0daefd8',\n",
       " 'cf0b592f-ab44-44bd-b533-3e51959054ac',\n",
       " '4597bc58-a2f3-47a4-b83d-bdd5d6a0983b',\n",
       " '1fceffc9-aec0-41e0-95cd-4b9297de1071',\n",
       " 'a2a186d5-3f25-4528-bf78-5839c7ef0d1d',\n",
       " '1a417ebc-9f3c-4916-9b59-10b1565a5f2a',\n",
       " '6eafed65-8ac5-494b-afdc-28ea2a12a75d',\n",
       " '13e1df0f-0aa0-4b2e-9c00-4e2ad86274c4',\n",
       " '4ee5ed46-2b7e-4486-bcfe-1809b27ca02d',\n",
       " '158c1ff3-cbae-44aa-a27d-15783d6c380d',\n",
       " '22e29df0-aa2f-4f30-801a-10fa9eddb6ce',\n",
       " '97fa8393-506e-4d20-9a64-33e0ded9a8e8',\n",
       " '0734ed58-0dac-4da2-8f4b-a03a1cf7f615',\n",
       " '4ef809bd-6970-410f-9265-e0b7df9e02d5',\n",
       " 'd9ba9985-4e32-4f0d-ba04-53d92f590798',\n",
       " '0948237b-b697-4b7c-9219-dbb75fe7b705',\n",
       " '47fc752c-92ad-492d-9c46-9d6f9f649026',\n",
       " 'ffb924e1-984a-41fc-92eb-70b13e4d41d3',\n",
       " '000ce103-fdd4-404f-8126-b63f3c8ccd0f',\n",
       " '1d37b868-0e28-43b0-b0ba-adcd456f3897',\n",
       " '633af820-498c-4ead-9343-b7dded9e47ab',\n",
       " '65ea73d0-02e8-475e-bec6-2caabcc9a314',\n",
       " '90f3555c-c514-4b86-9eca-a28dbd6de09b',\n",
       " '5f40f9fd-7c82-44e0-ab60-243cee2b71f7',\n",
       " '0e776b50-222c-45a3-a94d-b362505db1a1',\n",
       " '96ca1191-3ce6-4f58-a700-88832302a2b4',\n",
       " 'b610e417-a044-4628-bd9b-8f623538019a',\n",
       " '0a531f23-87dc-42f7-944b-d3cfb52ee494',\n",
       " '3b53b8b1-08e0-4182-bbad-217b8c5066d0',\n",
       " '2b3609a3-f16a-4547-899b-ca7eb0497f78',\n",
       " '09abb996-3e93-41fd-b2fd-a9d9abfead43',\n",
       " '4abe49ac-dc42-4ba0-b7c0-b432fcf4c3c5',\n",
       " 'cc38d668-f2e2-4360-ac8d-f7e7bb77099f',\n",
       " '13753b32-9e5b-42fd-83ea-dfd10f4f4f26',\n",
       " 'a908c51f-9bfe-406b-b2f6-17e5743088fc',\n",
       " '8197b2f0-990d-405c-8c69-36bff2b56ffd',\n",
       " 'a70cddf2-04d0-4309-b895-ba18799795a0',\n",
       " 'b8db1d75-967e-4fde-b65d-aeb575f6ebc6',\n",
       " '7230a3ff-2d03-410a-8981-838654578884',\n",
       " '0a54000a-c7fd-4259-85b9-d47d4485f8d3',\n",
       " 'c0ad389b-2f48-4fa3-a301-8128aa1e4b2f',\n",
       " '40e499b8-e48b-4612-a9f3-abb9756b0aa0',\n",
       " '214bda45-c54c-4190-95b4-648115079212',\n",
       " 'dd124574-4c70-4efd-9334-33e2f4804111',\n",
       " 'b52499e9-55bf-452d-be9e-18f543ec410c',\n",
       " '5a67c51f-5f04-47b3-82f7-92e64e9c3de0',\n",
       " '1cdfc0e8-247d-48b6-b39d-1d7f27f345ee',\n",
       " 'fa9687b0-a491-4d00-9904-670d99d01ad3',\n",
       " '7d9b80a9-bf00-429e-baba-e7858f4e78ed',\n",
       " 'f46a2c09-21d8-482b-b0be-d2ebb0771605',\n",
       " '5f436308-64ef-45ea-bbb6-5622688d26a6',\n",
       " '5cdd8fe7-15ca-48a8-b553-b9970ceea4d6',\n",
       " '4526c259-38d9-4d53-8453-df9ff8763927',\n",
       " '6efac733-5d2c-4956-94b1-11a2f0c90240',\n",
       " 'dcaf7b36-91be-452c-8463-378712f9f887',\n",
       " '671873b6-bc7e-48da-bfc1-add5fd05356f',\n",
       " '61f2f78b-1a80-4207-a31f-abd798ca7a6e',\n",
       " '929dd740-e977-407d-8f59-c55062bba9da',\n",
       " '9ec45878-01aa-487e-843c-5117a7594444',\n",
       " '830293f0-13f1-4506-a555-3235252b1bdb',\n",
       " 'c6a05e52-7d4a-4cce-ab53-5bc813e3b9a9',\n",
       " '7587ce21-17a2-48a0-bb5b-07b85e26d468',\n",
       " 'e5c4cb80-9d87-4152-b318-614a0bfc7377',\n",
       " 'd245cedc-550e-41b6-a421-69b04346317a',\n",
       " 'b2aa1440-a51a-4401-8819-c1f2f1642fb1',\n",
       " '83c0742e-2854-41e5-8bef-42142a698775',\n",
       " '6e88c9de-6d39-496b-9bf1-b4ab44cad302',\n",
       " '93a3a8d8-ab6a-45e2-b52e-695410e01484',\n",
       " '8130c81b-eb21-4d7f-ade3-a8300511baa7',\n",
       " '25377182-c48a-4428-8153-0a6cee077d27',\n",
       " '64080ff2-3fbe-4a53-a739-88264096b81d',\n",
       " '0721b6c0-f5cd-4094-8603-21ce73336939',\n",
       " '2585b08d-c2a3-42cc-b669-1b95e81ba47d',\n",
       " '83d32532-43cb-4942-a077-5ea73677b965',\n",
       " '92a29855-cecf-4c89-a8f9-2884f26880f3',\n",
       " '0a1dbea0-746c-404e-95e0-d4f94904a19c',\n",
       " '8d3a9fb2-b5e0-47e5-b307-5a4033f8d724',\n",
       " '0c04af3f-0d1c-4491-9893-c5646c903282',\n",
       " '9b6832f6-0f58-4435-9a55-f82456d73ff4',\n",
       " 'f760a724-3f97-41f0-a28d-d328b582aaa9',\n",
       " '40dd3abd-d79a-498f-b977-e4de4a22cd86',\n",
       " '18583521-90b1-4b67-a09d-be86f04b83ba',\n",
       " 'd3c766eb-d4a4-4989-82ed-d64b9db86bb2',\n",
       " '76059664-2adc-46b7-9a4f-d1e3316d1099',\n",
       " '6a670f91-d639-4b34-92d5-6e64ff64d21d',\n",
       " '486e2e5a-8610-4628-9353-8192acdab09b',\n",
       " '22d04bd9-1d26-4a4a-b3ed-c1887b0ee050',\n",
       " 'b1f55c59-5730-4786-b330-0bc7a1c584bf',\n",
       " '9e0bc1bb-0b10-46fd-a57e-bbdbc45eac23',\n",
       " '17c4b33d-cb75-4abc-971d-ebaa87a229f8',\n",
       " '5a47e6ac-915f-4df2-bd3f-545788230aaa',\n",
       " '148fb96f-15c8-4f04-96c6-e92e225c48b6',\n",
       " 'c6c05548-35c0-4e5b-9472-96fa83d10cdc',\n",
       " 'bb864361-3cf9-4d17-bca4-a6d8a4f00032',\n",
       " 'c8800f48-edfe-439f-91e5-a4fc5c6e45b4',\n",
       " '71eed249-9e75-406e-9934-0ebe075910d2',\n",
       " 'f6beb713-d35c-470e-a3c0-802bae2eb23c',\n",
       " '9a25ca98-00b1-4fe1-a875-ac25f967bc48',\n",
       " 'edb3862c-7304-498e-b8e4-1b1cde79dd7d',\n",
       " 'f4a24006-d7d5-4c90-9c14-f895440379e5',\n",
       " '64d3e2df-3e3d-4ebd-8102-dc87791ab7fd',\n",
       " 'cabb25e6-8e29-4ee2-9422-0a990b400066',\n",
       " '513cabe6-af66-4e41-bd43-0de17a184e5d',\n",
       " 'bb830ce1-dc12-48d4-8477-2d5a7c2e5d2c',\n",
       " '53b72ecd-f78a-44a8-bcd9-6c2b33be9c08',\n",
       " '7e68e496-e511-4ed8-991f-6964ff7f451d',\n",
       " '400ae9c0-7ba3-4ade-bdbd-c558f99cfd33',\n",
       " '16636a1b-ab5d-479e-b36f-6c7859c60140',\n",
       " '92f3990b-37eb-4d1a-8bc7-e0abc8c4805f']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(doc_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query: Retriver Setup\n",
    "\n",
    "Configures vector store retriever to fetch 4 most relevant chunks per query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(k=3, search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Local LLM Configuration\n",
    "\n",
    "Initializes Ollama model (llama3.2 3B instruct) in JSON output mode with:\n",
    "- Base model: llama3.2 3B instruct (FP16)\n",
    "- Temerature: 0 for deterministic outputs\n",
    "- Format: JSON for structured responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"llama3.2:3b-instruct-fp16\"\n",
    "llm = ChatOllama(model=MODEL_NAME, temperature=0)\n",
    "json_llm = ChatOllama(model=MODEL_NAME, temperature=0, format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture: Base Evaluator Class\n",
    "\n",
    "Abstract base class defining common methods and attributes for both graders and QA:\n",
    "- Handles message construction and LLM invocation\n",
    "- Supports both evaluation and generation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseEvaluator(ABC):\n",
    "    def __init__(self, llm, retriever):\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "\n",
    "    def get_context(self, question: str) -> str:\n",
    "        docs = self.retriever.invoke(question)\n",
    "        return [doc.page_content for doc in docs]\n",
    "    \n",
    "    def evaluate(self, input_text: str, contexts: List[str] = None) -> Union[Dict, str]:\n",
    "        if contexts is None:\n",
    "            contexts = self.get_context(input_text) \n",
    "        return self._process_contexts(contexts, input_text)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _process_contexts(self, contexts: List[str], input_text: str) -> Union[Dict, str]:\n",
    "        \"\"\"Process contexts according to evaluator type (grade/answer/etc).\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Relevance Grader\n",
    "\n",
    "Implements grading logic to assess document relevance to queries:\n",
    "- Returns binary relevance score for each context\n",
    "- Aggregates multiple context scores into final assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelevanceGrader(BaseEvaluator):\n",
    "    def __init__(self, llm, retriever):\n",
    "        super().__init__(llm, retriever)\n",
    "        self.system_prompt = \"\"\"You are a grader assessing relevance of a retrieved context to a user question.\n",
    "        If the context contains keyword(s) or semantic meaning related to the question, grade it as relevant.\"\"\"\n",
    "\n",
    "        self.human_prompt_template = \"\"\"Here is the retrieved context: \\n\\n {context} \\n\\n Here is the user question: \\n\\n {input_text}.\n",
    "\n",
    "        Review carefully and objectively assess whether the context contains at least some information that is relevant to the question.\n",
    "\n",
    "        Return JSON with 'binary_score': 'yes' if context has ANY connection to the topic (direct mentions, related technology, underlying concepts, or applications), 'no' ONLY if completely unrelated.\"\"\"\n",
    "        \n",
    "    def _process_contexts(self, contexts: List[str], input_text: str) -> Dict:\n",
    "        relevant_contexts = []\n",
    "        scores = []\n",
    "        for context in contexts:\n",
    "            messages = [\n",
    "                SystemMessage(content=self.system_prompt),\n",
    "                HumanMessage(content=self.human_prompt_template.format(\n",
    "                    context=context,\n",
    "                    input_text=input_text\n",
    "                ))\n",
    "            ]\n",
    "            result = self.llm.invoke(messages)\n",
    "            is_relevant = json.loads(result.content)['binary_score'] == 'yes'\n",
    "            scores.append(is_relevant)\n",
    "            if is_relevant:\n",
    "                relevant_contexts.append(context)\n",
    "\n",
    "        return {\n",
    "            \"relevance_percentage\": len(relevant_contexts) / len(contexts) * 100,\n",
    "            \"relevant_contexts\": relevant_contexts\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Quesiton Answering\n",
    "\n",
    "Implements context-aware QA using filtered relevant contexts to generate answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswering(BaseEvaluator):\n",
    "    def __init__(self, llm, retriever):\n",
    "        super().__init__(llm, retriever)\n",
    "        self.prompt_template=\"\"\"You are an assistant for question-answering tasks.\n",
    "        \n",
    "        Context:\n",
    "        {context}\n",
    "        \n",
    "        Question:\n",
    "        {input_text}\n",
    "        \n",
    "        Provide an answer using only the above context.\n",
    "        \n",
    "        Answer:\"\"\"\n",
    "\n",
    "    def _process_contexts(self, contexts: List[str], input_text: str) -> str:\n",
    "        if not contexts:\n",
    "            return \"No relevant context found to answer this question.\"\n",
    "        \n",
    "        combined_context = \"\\n\\n\".join(contexts)\n",
    "        messages = [HumanMessage(content=self.prompt_template.format(\n",
    "            context=combined_context,\n",
    "            input_text=input_text\n",
    "        ))]\n",
    "        return self.llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation: Hallucination Grader\n",
    "\n",
    "Evaluates answers against contexts for factual accuracy:\n",
    "- Binary grading system with detailed explanations\n",
    "- Validates answer groundedness in provided contexts\n",
    "- Identifies unsupported claims or hallucinated information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HallucinationGrader(BaseEvaluator):\n",
    "    def __init__(self, llm, retriever):\n",
    "        super().__init__(llm, retriever)\n",
    "        self.system_prompt=\"\"\"You are a hallucination grader.\n",
    "        You will be given actual contexts and an answer.\n",
    "        Here is the grade criteria to follow:\n",
    "        (1) Ensure the answer is grounded in the actual contexts.\n",
    "        (2) Ensure the answer does not contain \"hallucinated\" information outside the scope of the actual contexts.\n",
    "        Score:\n",
    "        A score of yes means that the answer meets all of the criteria. This is the highest score.\n",
    "        A score of no means that the answer does not meet all of the criteria. This is the lowest possible score. \n",
    "        Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
    "        Avoid simply stating the correct answer at the outset.\n",
    "        \"\"\"\n",
    "        self.human_prompt_template=\"\"\"actual contexts: \\n\\n {contexts} \\n\\n answer: {input_text}\n",
    "        Return JSON with two keys, binary_score is 'yes' or 'no' score to indicate whether the answer is grounded in the FACTS. And a key, explanation, that contains an explanation of the score.\"\"\"\n",
    "\n",
    "    def _process_contexts(self, contexts: List[str], input_text: str) -> str:\n",
    "        combined_context = \"\\n\\n\".join(contexts)\n",
    "        messages = [\n",
    "            SystemMessage(content=self.system_prompt),\n",
    "            HumanMessage(content=self.human_prompt_template.format(\n",
    "                contexts=combined_context,\n",
    "                input_text=input_text\n",
    "            ))\n",
    "        ]\n",
    "        return json.loads(self.llm.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline: Question-Answer Flow\n",
    "\n",
    "Pipeline integration for context-aware QA:\n",
    "- Takes user question and processes through grader and QA modules\n",
    "- RelevanceGrader filters and scores context relevance\n",
    "- QuestionAnswering generates answers from relevant contexts\n",
    "- HallucinationGrader validates answer factual accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance: 100.0%\n",
      "Answer: Vision Transformer works by analyzing its internal representations. The first layer linearly projects flattened patches into a lower-dimensional space. A learned position embedding is then added to the patch representations, allowing the model to encode distance within the image in the similarity of position embeddings. This process is similar to how a standard Transformer encoder processes a sequence of tokens in NLP.\n",
      "Hallucination Check: Not hallucinated\n",
      "Explanation: The answer is grounded in the actual contexts provided because it accurately describes the internal representations of the Vision Transformer as analyzed in the text. Specifically, the first layer projects flattened patches into a lower-dimensional space (Eq. 1), and a learned position embedding is added to the patch representations, allowing the model to encode distance within the image in the similarity of position embeddings. This process is consistent with how a standard Transformer encoder processes a sequence of tokens in NLP, as mentioned in the text. The answer does not contain any 'hallucinated' information outside the scope of the actual contexts.\n"
     ]
    }
   ],
   "source": [
    "question = \"How does vision transformer work?\"\n",
    "relevance_grader = RelevanceGrader(json_llm, retriever)\n",
    "qa = QuestionAnswering(llm, retriever)\n",
    "hallucination_grader = HallucinationGrader(json_llm, retriever)\n",
    "\n",
    "relevance_results = relevance_grader.evaluate(question)\n",
    "answer = qa.evaluate(question, relevance_results[\"relevant_contexts\"])\n",
    "hallucination_results = hallucination_grader.evaluate(answer, relevance_results[\"relevant_contexts\"])\n",
    "\n",
    "print(f\"Relevance: {relevance_results['relevance_percentage']}%\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Hallucination Check: {'Not hallucinated' if hallucination_results['binary_score']==\"yes\" else \"Contains hallucination\"}\")\n",
    "print(f\"Explanation: {hallucination_results['explanation']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved contexts: 3\n",
      "\n",
      "Context 1:\n",
      "4.5 I NSPECTING VISION TRANSFORMER\n",
      "Input\n",
      " Attention\n",
      "Figure 6: Representative ex-\n",
      "amples of attention from the\n",
      "output token to the input\n",
      "space. See Appendix D.7 for\n",
      "details.\n",
      "To begin to understand how the Vision Transformer processes im-\n",
      "age data, we analyze its internal representations. The ﬁrst layer of\n",
      "the Vision Transformer linearly projects the ﬂattened patches into a\n",
      "lower-dimensional space (Eq. 1). Figure 7 (left) shows the top prin-\n",
      "cipal components of the the learned embedding ﬁlters. The com-\n",
      "ponents resemble plausible basis functions for a low-dimensional\n",
      "representation of the ﬁne structure within each patch.\n",
      "After the projection, a learned position embedding is added to the\n",
      "patch representations. Figure 7 (center) shows that the model learns\n",
      "to encode distance within the image in the similarity of position em-\n",
      "beddings, i.e. closer patches tend to have more similar position em-\n",
      "beddings. Further, the row-column structure appears; patches in the\n",
      "\n",
      "Context 2:\n",
      "using self-attention in computer vision, we do not introduce image-speciﬁc inductive biases into\n",
      "the architecture apart from the initial patch extraction step. Instead, we interpret an image as a\n",
      "sequence of patches and process it by a standard Transformer encoder as used in NLP. This simple,\n",
      "yet scalable, strategy works surprisingly well when coupled with pre-training on large datasets.\n",
      "Thus, Vision Transformer matches or exceeds the state of the art on many image classiﬁcation\n",
      "datasets, whilst being relatively cheap to pre-train.\n",
      "While these initial results are encouraging, many challenges remain. One is to apply ViT to other\n",
      "computer vision tasks, such as detection and segmentation. Our results, coupled with those in Carion\n",
      "et al. (2020), indicate the promise of this approach. Another challenge is to continue exploring self-\n",
      "supervised pre-training methods. Our initial experiments show improvement from self-supervised\n",
      "\n",
      "Context 3:\n",
      "overall structure in place. We show that this reliance on CNNs is not necessary\n",
      "and a pure transformer applied directly to sequences of image patches can perform\n",
      "very well on image classiﬁcation tasks. When pre-trained on large amounts of\n",
      "data and transferred to multiple mid-sized or small image recognition benchmarks\n",
      "(ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent\n",
      "results compared to state-of-the-art convolutional networks while requiring sub-\n",
      "stantially fewer computational resources to train.1\n",
      "1 I NTRODUCTION\n",
      "Self-attention-based architectures, in particular Transformers (Vaswani et al., 2017), have become\n",
      "the model of choice in natural language processing (NLP). The dominant approach is to pre-train on\n",
      "a large text corpus and then ﬁne-tune on a smaller task-speciﬁc dataset (Devlin et al., 2019). Thanks\n",
      "to Transformers’ computational efﬁciency and scalability, it has become possible to train models of\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(question)\n",
    "print(f\"Retrieved contexts: {len(docs)}\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\nContext {i+1}:\")\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
